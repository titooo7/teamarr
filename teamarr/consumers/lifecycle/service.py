"""Channel lifecycle service.

Full channel lifecycle management with Dispatcharr integration.
Handles channel creation, deletion, settings sync, and EPG association.
"""

import json
import logging
import threading
from sqlite3 import Connection
from typing import Any

from teamarr.core import Event
from teamarr.templates import ContextBuilder, TemplateResolver

from .timing import ChannelLifecycleManager
from .types import (
    ChannelCreationResult,
    CreateTiming,
    DeleteTiming,
    StreamProcessResult,
    generate_event_tvg_id,
)

logger = logging.getLogger(__name__)


class ChannelLifecycleService:
    """Full channel lifecycle management with Dispatcharr integration.

    Handles:
    - Channel creation from matched streams
    - Channel deletion based on timing
    - Settings sync (name, number, streams, logo, profiles)
    - EPG association after refresh
    - Duplicate handling (consolidate, separate, ignore)
    - Exception keyword handling

    Usage:
        from teamarr.dispatcharr import DispatcharrClient, ChannelManager, EPGManager, LogoManager
        from teamarr.database import get_db

        with DispatcharrClient(url, username, password) as client:
            service = ChannelLifecycleService(
                db_factory=get_db,
                channel_manager=ChannelManager(client),
                logo_manager=LogoManager(client),
                epg_manager=EPGManager(client),
                create_timing='same_day',
                delete_timing='day_after',
            )

            # Process matched streams
            result = service.process_matched_streams(matches, group_config)

            # Delete expired channels
            result = service.process_scheduled_deletions()
    """

    def __init__(
        self,
        db_factory: Any,
        sports_service: Any,
        channel_manager: Any = None,
        logo_manager: Any = None,
        epg_manager: Any = None,
        create_timing: CreateTiming = "same_day",
        delete_timing: DeleteTiming = "day_after",
        default_duration_hours: float = 3.0,
        sport_durations: dict[str, float] | None = None,
        timezone: str = "America/New_York",
    ):
        """Initialize the lifecycle service.

        Args:
            db_factory: Factory function that returns a database connection
            sports_service: SportsDataService for template variable resolution (required)
            channel_manager: ChannelManager instance for Dispatcharr operations
            logo_manager: LogoManager instance for logo operations
            epg_manager: EPGManager instance for EPG operations
            create_timing: When to create channels
            delete_timing: When to delete channels
            default_duration_hours: Default event duration
            sport_durations: Per-sport duration mapping (basketball, football, etc.)
            timezone: User timezone for timing calculations

        Raises:
            ValueError: If sports_service is not provided
        """
        if sports_service is None:
            raise ValueError("sports_service is required for template variable resolution")

        self._db_factory = db_factory
        self._sports_service = sports_service
        self._channel_manager = channel_manager
        self._logo_manager = logo_manager
        self._epg_manager = epg_manager
        self._timezone = timezone

        # Timing manager for create/delete decisions
        self._timing_manager = ChannelLifecycleManager(
            create_timing=create_timing,
            delete_timing=delete_timing,
            default_duration_hours=default_duration_hours,
            sport_durations=sport_durations,
        )

        # Thread lock for Dispatcharr operations
        self._dispatcharr_lock = threading.Lock()

        # Cache exception keywords
        self._exception_keywords: list | None = None

        # Template engine
        self._context_builder = ContextBuilder(sports_service)
        self._resolver = TemplateResolver()

    @property
    def dispatcharr_enabled(self) -> bool:
        """Check if Dispatcharr integration is enabled."""
        return self._channel_manager is not None

    def clear_caches(self) -> None:
        """Clear all Dispatcharr caches.

        Should be called at the start of EPG generation to ensure fresh data.
        """
        if self._channel_manager:
            self._channel_manager.clear_cache()
        if self._logo_manager:
            self._logo_manager.clear_cache()
        self._exception_keywords = None

    def _get_exception_keywords(self, conn: Connection) -> list:
        """Get exception keywords with caching."""
        if self._exception_keywords is None:
            from teamarr.database.channels import get_exception_keywords

            self._exception_keywords = get_exception_keywords(conn)
        return self._exception_keywords

    def _check_exception_keyword(
        self,
        stream_name: str,
        conn: Connection,
    ) -> tuple[str | None, str | None]:
        """Check if stream name matches any exception keyword.

        Returns:
            Tuple of (matched_keyword, behavior) or (None, None)
        """
        from teamarr.database.channels import check_exception_keyword

        keywords = self._get_exception_keywords(conn)
        return check_exception_keyword(stream_name, keywords)

    def process_matched_streams(
        self,
        matched_streams: list[dict],
        group_config: dict,
        template: dict | None = None,
    ) -> StreamProcessResult:
        """Process matched streams and create/update channels as needed.

        Handles all three duplicate modes:
        - consolidate: All streams for same event → one channel
        - separate: Each stream → its own channel
        - ignore: First stream wins, skip duplicates

        Args:
            matched_streams: List of dicts with 'stream', 'event' keys
            group_config: Event EPG group configuration
            template: Optional template for channel naming

        Returns:
            StreamProcessResult with created, existing, skipped, errors
        """
        from teamarr.database.channels import (
            find_existing_channel,
            log_channel_history,
        )

        result = StreamProcessResult()

        try:
            with self._db_factory() as conn:
                # Get group settings
                group_id = group_config.get("id")
                duplicate_mode = group_config.get("duplicate_event_handling", "consolidate")

                # Debug: count active channels for this group
                cursor = conn.execute(
                    """SELECT COUNT(*) FROM managed_channels
                       WHERE event_epg_group_id = ? AND deleted_at IS NULL""",
                    (group_id,),
                )
                active_count = cursor.fetchone()[0]
                if active_count > 0:
                    logger.debug(
                        f"Group {group_id}: {active_count} active channels before processing"
                    )
                channel_group_id = group_config.get("channel_group_id")
                stream_profile_id = group_config.get("stream_profile_id")
                channel_profile_ids = self._parse_profile_ids(
                    group_config.get("channel_profile_ids")
                )

                for matched in matched_streams:
                    stream = matched.get("stream", {})
                    event = matched.get("event")

                    if not event:
                        result.errors.append(
                            {
                                "stream": stream.get("name", "Unknown"),
                                "error": "No event data",
                            }
                        )
                        continue

                    event_id = event.id
                    event_provider = getattr(event, "provider", "espn")
                    stream_name = stream.get("name", "")
                    stream_id = stream.get("id")

                    # Check exception keyword
                    matched_keyword, keyword_behavior = self._check_exception_keyword(
                        stream_name, conn
                    )

                    # Determine effective duplicate mode
                    effective_mode = keyword_behavior if keyword_behavior else duplicate_mode

                    # Find existing channel based on mode
                    existing = find_existing_channel(
                        conn=conn,
                        group_id=group_id,
                        event_id=event_id,
                        event_provider=event_provider,
                        exception_keyword=matched_keyword,
                        stream_id=stream_id,
                        mode=effective_mode,
                    )

                    if existing:
                        # Handle based on effective mode
                        channel_result = self._handle_existing_channel(
                            conn=conn,
                            existing=existing,
                            stream=stream,
                            event=event,
                            effective_mode=effective_mode,
                            matched_keyword=matched_keyword,
                            group_config=group_config,
                            template=template,
                        )
                        # None means Dispatcharr channel missing - fall through to create new
                        if channel_result is not None:
                            result.merge(channel_result)
                            continue

                    # Check if we should create based on timing
                    decision = self._timing_manager.should_create_channel(
                        event,
                        stream_exists=True,
                    )

                    if not decision.should_act:
                        logger.debug(
                            f"Skipping channel creation for '{stream_name}': {decision.reason}"
                        )
                        result.skipped.append(
                            {
                                "stream": stream_name,
                                "event_id": event_id,
                                "reason": decision.reason,
                            }
                        )
                        continue

                    # Cross-group overlap handling for multi-league groups
                    # Multi-league groups are processed LAST, so single-league channels exist
                    leagues = group_config.get("leagues", [])
                    is_multi_league = len(leagues) > 1
                    overlap_handling = group_config.get("overlap_handling", "add_stream")

                    if is_multi_league and overlap_handling != "create_all":
                        cross_group_result = self._handle_cross_group_overlap(
                            conn=conn,
                            event=event,
                            stream=stream,
                            group_id=group_id,
                            matched_keyword=matched_keyword,
                            overlap_handling=overlap_handling,
                            group_config=group_config,
                            template=template,
                        )

                        if cross_group_result is not None:
                            # Stream was handled (added to existing or skipped)
                            result.merge(cross_group_result)
                            continue
                        # cross_group_result is None means: no existing channel found
                        # and not add_only mode, so fall through to create new channel

                    # Create new channel
                    channel_result = self._create_channel(
                        conn=conn,
                        event=event,
                        stream=stream,
                        group_config=group_config,
                        template=template,
                        matched_keyword=matched_keyword,
                        channel_group_id=channel_group_id,
                        stream_profile_id=stream_profile_id,
                        channel_profile_ids=channel_profile_ids,
                    )

                    if channel_result.success:
                        logger.info(
                            f"Created channel {channel_result.dispatcharr_channel_id} "
                            f"(#{channel_result.channel_number}): {stream_name}"
                        )
                        result.created.append(
                            {
                                "stream": stream_name,
                                "event_id": event_id,
                                "channel_id": channel_result.channel_id,
                                "dispatcharr_channel_id": channel_result.dispatcharr_channel_id,
                                "channel_number": channel_result.channel_number,
                                "tvg_id": channel_result.tvg_id,
                            }
                        )

                        # Log history
                        log_channel_history(
                            conn=conn,
                            managed_channel_id=channel_result.channel_id,
                            change_type="created",
                            change_source="epg_generation",
                            notes=f"Created from stream '{stream_name}'",
                        )
                    else:
                        logger.warning(
                            f"Failed to create channel for '{stream_name}': {channel_result.error}"
                        )
                        result.errors.append(
                            {
                                "stream": stream_name,
                                "event_id": event_id,
                                "error": channel_result.error,
                            }
                        )

        except Exception as e:
            logger.exception("Error processing matched streams")
            result.errors.append({"error": str(e)})

        return result

    def _handle_cross_group_overlap(
        self,
        conn: Connection,
        event: Event,
        stream: dict,
        group_id: int,
        matched_keyword: str | None,
        overlap_handling: str,
        group_config: dict,
        template: dict | None,
    ) -> StreamProcessResult | None:
        """Handle cross-group overlap for multi-league groups.

        Multi-league groups are processed LAST, so single-league channels
        should already exist. This method checks for existing channels in
        OTHER groups and handles based on overlap_handling mode:

        - add_stream: Add to existing OR create new (returns None to create)
        - add_only: Add to existing OR skip (never create new)
        - skip: Skip if existing found, create if not (returns None to create)
        - create_all: Not called (handled by caller)

        Args:
            conn: Database connection
            event: Event to check
            stream: Stream data
            group_id: Current group ID (to exclude from search)
            matched_keyword: Exception keyword if matched
            overlap_handling: One of add_stream, add_only, skip
            group_config: Full group configuration
            template: Template configuration

        Returns:
            StreamProcessResult if stream was handled (added/skipped)
            None if no existing channel found and should create new
        """
        from teamarr.database.channels import (
            add_stream_to_channel,
            find_any_channel_for_event,
            get_next_stream_priority,
            log_channel_history,
            stream_exists_on_channel,
        )

        stream_name = stream.get("name", "")
        stream_id = stream.get("id")
        event_id = event.id
        event_provider = getattr(event, "provider", "espn")

        # First try to find channel with matching keyword
        existing = None
        if matched_keyword:
            existing = find_any_channel_for_event(
                conn=conn,
                event_id=event_id,
                event_provider=event_provider,
                exclude_group_id=group_id,
                exception_keyword=matched_keyword,
            )

        # If no keyword match, find any channel for the event
        if not existing:
            existing = find_any_channel_for_event(
                conn=conn,
                event_id=event_id,
                event_provider=event_provider,
                exclude_group_id=group_id,
                any_keyword=True,
            )

        if existing:
            # Found existing channel in another group
            if overlap_handling == "skip":
                # Skip mode: don't add stream, don't create channel
                result = StreamProcessResult()
                result.skipped.append(
                    {
                        "stream": stream_name,
                        "event_id": event_id,
                        "reason": "event_owned_by_other_group",
                        "existing_channel_id": existing.id,
                        "existing_group_id": existing.event_epg_group_id,
                    }
                )
                logger.debug(
                    f"Skipped '{stream_name}' - event owned by group {existing.event_epg_group_id}"
                )
                return result
            else:
                # add_stream or add_only: add stream to existing channel
                result = StreamProcessResult()

                if stream_exists_on_channel(conn, existing.id, stream_id):
                    result.existing.append(
                        {
                            "stream": stream_name,
                            "channel_id": existing.id,
                            "channel_number": existing.channel_number,
                            "action": "already_present",
                        }
                    )
                    return result

                # Add stream to existing channel
                priority = get_next_stream_priority(conn, existing.id)
                add_stream_to_channel(
                    conn=conn,
                    managed_channel_id=existing.id,
                    dispatcharr_stream_id=stream_id,
                    source_group_id=group_id,
                    source_group_type="cross_group",
                    stream_name=stream_name,
                    m3u_account_id=group_config.get("m3u_account_id"),
                    m3u_account_name=group_config.get("m3u_account_name"),
                    priority=priority,
                )

                # Sync with Dispatcharr
                if self._channel_manager and existing.dispatcharr_channel_id:
                    with self._dispatcharr_lock:
                        disp_channel = self._channel_manager.get_channel(
                            existing.dispatcharr_channel_id
                        )
                        if disp_channel:
                            current_streams = list(disp_channel.streams)
                            if stream_id not in current_streams:
                                current_streams.append(stream_id)
                                self._channel_manager.update_channel(
                                    existing.dispatcharr_channel_id,
                                    {"streams": tuple(current_streams)},
                                )

                log_channel_history(
                    conn=conn,
                    managed_channel_id=existing.id,
                    change_type="stream_added",
                    change_source="cross_group_enforcement",
                    notes=f"Added '{stream_name}' from multi-league group {group_id}",
                )

                result.existing.append(
                    {
                        "stream": stream_name,
                        "channel_id": existing.id,
                        "channel_number": existing.channel_number,
                        "action": "added_cross_group",
                        "source_group_id": group_id,
                    }
                )

                logger.debug(
                    f"Added '{stream_name}' to existing channel #{existing.channel_number} "
                    f"(cross-group from {group_id})"
                )
                return result

        else:
            # No existing channel found in other groups
            if overlap_handling == "add_only":
                # add_only mode: don't create new channel, skip stream
                result = StreamProcessResult()
                result.skipped.append(
                    {
                        "stream": stream_name,
                        "event_id": event_id,
                        "reason": "no_existing_channel_for_add_only",
                    }
                )
                logger.debug(
                    f"Skipped '{stream_name}' - add_only mode and no existing channel"
                )
                return result
            else:
                # add_stream or skip mode with no existing channel: create new
                # Return None to signal caller should create channel
                return None

    def _handle_existing_channel(
        self,
        conn: Connection,
        existing: Any,
        stream: dict,
        event: Event,
        effective_mode: str,
        matched_keyword: str | None,
        group_config: dict,
        template: dict | None,
    ) -> StreamProcessResult | None:
        """Handle an existing channel based on duplicate mode.

        Returns:
            StreamProcessResult if channel was handled successfully
            None if Dispatcharr channel is missing and caller should create new
        """
        from teamarr.database.channels import (
            add_stream_to_channel,
            get_next_stream_priority,
            log_channel_history,
            stream_exists_on_channel,
        )

        from teamarr.database.channels import mark_channel_deleted

        result = StreamProcessResult()
        stream_name = stream.get("name", "")
        stream_id = stream.get("id")

        # Verify channel exists in Dispatcharr
        # If missing, mark as deleted and return None to signal caller to create new
        if self._channel_manager and existing.dispatcharr_channel_id:
            with self._dispatcharr_lock:
                disp_channel = self._channel_manager.get_channel(existing.dispatcharr_channel_id)
                if not disp_channel:
                    # Channel missing from Dispatcharr - mark old record deleted
                    # Return None to signal caller should create new channel
                    logger.warning(
                        f"Channel {existing.dispatcharr_channel_id} missing from "
                        f"Dispatcharr, marking deleted and will create new: {existing.channel_name}"
                    )
                    mark_channel_deleted(
                        conn, existing.id,
                        reason=f"Missing from Dispatcharr (ID {existing.dispatcharr_channel_id})"
                    )
                    log_channel_history(
                        conn=conn,
                        managed_channel_id=existing.id,
                        change_type="deleted",
                        change_source="lifecycle",
                        notes="Channel missing from Dispatcharr, marked for cleanup",
                    )
                    # Return None to signal caller to create new channel
                    return None

        if effective_mode == "ignore":
            # Skip - don't add stream
            result.existing.append(
                {
                    "stream": stream_name,
                    "channel_id": existing.dispatcharr_channel_id,
                    "channel_number": existing.channel_number,
                    "action": "ignored",
                }
            )
            return result

        if effective_mode == "consolidate":
            # Add stream to existing channel if not already present
            if not stream_exists_on_channel(conn, existing.id, stream_id):
                # Add to DB
                priority = get_next_stream_priority(conn, existing.id)
                add_stream_to_channel(
                    conn=conn,
                    managed_channel_id=existing.id,
                    dispatcharr_stream_id=stream_id,
                    stream_name=stream_name,
                    priority=priority,
                    exception_keyword=matched_keyword,
                    m3u_account_id=stream.get("m3u_account_id"),
                )

                # Add to Dispatcharr
                if self._channel_manager:
                    with self._dispatcharr_lock:
                        current = self._channel_manager.get_channel(existing.dispatcharr_channel_id)
                        if current:
                            # streams is already tuple[int, ...] of stream IDs
                            current_streams = list(current.streams) if current.streams else []
                            if stream_id not in current_streams:
                                current_streams.append(stream_id)
                                self._channel_manager.update_channel(
                                    existing.dispatcharr_channel_id,
                                    {"streams": current_streams},
                                )

                # Log history
                log_channel_history(
                    conn=conn,
                    managed_channel_id=existing.id,
                    change_type="stream_added",
                    change_source="epg_generation",
                    notes=f"Added stream '{stream_name}' (consolidate mode)",
                )

                result.streams_added.append(
                    {
                        "stream": stream_name,
                        "channel_id": existing.dispatcharr_channel_id,
                        "channel_name": existing.channel_name,
                    }
                )

            result.existing.append(
                {
                    "stream": stream_name,
                    "channel_id": existing.dispatcharr_channel_id,
                    "channel_number": existing.channel_number,
                    "action": "consolidated",
                }
            )

        else:  # separate mode - channel found for this stream
            result.existing.append(
                {
                    "stream": stream_name,
                    "channel_id": existing.dispatcharr_channel_id,
                    "channel_number": existing.channel_number,
                    "action": "separate_exists",
                }
            )

        # Sync channel settings
        settings_result = self._sync_channel_settings(
            conn=conn,
            existing=existing,
            stream=stream,
            event=event,
            group_config=group_config,
            template=template,
        )
        result.merge(settings_result)

        return result

    def _create_channel(
        self,
        conn: Connection,
        event: Event,
        stream: dict,
        group_config: dict,
        template: dict | None,
        matched_keyword: str | None,
        channel_group_id: int | None,
        stream_profile_id: int | None,
        channel_profile_ids: list[int],
    ) -> ChannelCreationResult:
        """Create a new channel in DB and Dispatcharr."""
        from teamarr.database.channels import (
            add_stream_to_channel,
            create_managed_channel,
        )

        event_id = event.id
        event_provider = getattr(event, "provider", "espn")
        stream_name = stream.get("name", "")
        stream_id = stream.get("id")
        group_id = group_config.get("id")

        # Generate tvg_id
        tvg_id = generate_event_tvg_id(event_id, event_provider)

        # Generate channel name
        channel_name = self._generate_channel_name(event, template, matched_keyword)

        # Get channel number - use group's start number if configured
        group_start_number = group_config.get("channel_start_number")
        channel_number = self._get_next_channel_number(conn, group_id, group_start_number)
        if not channel_number:
            return ChannelCreationResult(
                success=False,
                error="Could not allocate channel number",
            )

        # Calculate delete time
        delete_time = self._timing_manager.calculate_delete_time(event)

        # Resolve logo URL from template (supports template variables)
        logo_url = self._resolve_logo_url(event, template)

        # Create in Dispatcharr
        dispatcharr_channel_id = None
        dispatcharr_uuid = None
        dispatcharr_logo_id = None

        if self._channel_manager:
            with self._dispatcharr_lock:
                # Upload logo if specified
                if logo_url and self._logo_manager:
                    logo_result = self._logo_manager.upload(
                        name=f"{channel_name} Logo",
                        url=logo_url,
                    )
                    if logo_result.success and logo_result.logo:
                        dispatcharr_logo_id = logo_result.logo.get("id")

                # Create channel
                create_result = self._channel_manager.create_channel(
                    name=channel_name,
                    channel_number=channel_number,
                    stream_ids=[stream_id],
                    tvg_id=tvg_id,
                    channel_group_id=channel_group_id,
                    logo_id=dispatcharr_logo_id,
                    stream_profile_id=stream_profile_id,
                )

                if not create_result.success:
                    return ChannelCreationResult(
                        success=False,
                        error=create_result.error or "Failed to create channel in Dispatcharr",
                    )

                if create_result.channel:
                    dispatcharr_channel_id = create_result.channel.get("id")
                    dispatcharr_uuid = create_result.channel.get("uuid")

                    # Add to channel profiles
                    for profile_id in channel_profile_ids:
                        self._channel_manager.add_to_profile(
                            profile_id,
                            dispatcharr_channel_id,
                        )

        # Create in DB - with rollback protection for Dispatcharr orphans
        try:
            managed_channel_id = create_managed_channel(
                conn=conn,
                event_epg_group_id=group_id,
                event_id=event_id,
                event_provider=event_provider,
                tvg_id=tvg_id,
                channel_name=channel_name,
                channel_number=channel_number,
                logo_url=logo_url,
                dispatcharr_channel_id=dispatcharr_channel_id,
                dispatcharr_uuid=dispatcharr_uuid,
                dispatcharr_logo_id=dispatcharr_logo_id,
                channel_group_id=channel_group_id,
                stream_profile_id=stream_profile_id,
                channel_profile_ids=channel_profile_ids,
                primary_stream_id=stream_id,
                exception_keyword=matched_keyword,
                home_team=event.home_team.name if event.home_team else None,
                away_team=event.away_team.name if event.away_team else None,
                event_date=event.start_time.isoformat() if event.start_time else None,
                event_name=event.name,
                league=event.league,
                sport=event.sport,
                # V1 Parity: Include venue and broadcast
                venue=event.venue.name if event.venue else None,
                broadcast=", ".join(event.broadcasts) if event.broadcasts else None,
                scheduled_delete_at=delete_time.isoformat() if delete_time else None,
                sync_status="in_sync" if dispatcharr_channel_id else "pending",
            )

            # Add stream to managed_channel_streams
            add_stream_to_channel(
                conn=conn,
                managed_channel_id=managed_channel_id,
                dispatcharr_stream_id=stream_id,
                stream_name=stream_name,
                priority=0,
                exception_keyword=matched_keyword,
                m3u_account_id=stream.get("m3u_account_id"),
            )

            # Commit immediately so next channel number query sees this channel
            conn.commit()

        except Exception as e:
            # DB insert failed - clean up the Dispatcharr channel to prevent orphans
            logger.error(f"DB insert failed for channel '{channel_name}': {e}")
            if dispatcharr_channel_id and self._channel_manager:
                try:
                    with self._dispatcharr_lock:
                        self._channel_manager.delete_channel(dispatcharr_channel_id)
                    logger.info(
                        f"Cleaned up Dispatcharr channel {dispatcharr_channel_id} after DB failure"
                    )
                except Exception as cleanup_err:
                    logger.warning(f"Failed to cleanup Dispatcharr channel: {cleanup_err}")

            return ChannelCreationResult(
                success=False,
                error=f"DB insert failed: {e}",
            )

        return ChannelCreationResult(
            success=True,
            channel_id=managed_channel_id,
            dispatcharr_channel_id=dispatcharr_channel_id,
            channel_number=channel_number,
            tvg_id=tvg_id,
        )

    def _generate_channel_name(
        self,
        event: Event,
        template,
        exception_keyword: str | None,
    ) -> str:
        """Generate channel name for an event.

        Uses full template engine (141 variables) when service is available.
        Otherwise falls back to default "Away @ Home" format.

        Args:
            event: Event data
            template: Can be dict, EventTemplateConfig dataclass, or None
            exception_keyword: Optional keyword for naming
        """
        # Get channel name format from template or use default
        name_format = None
        if template:
            # Handle both dict and dataclass template types
            if hasattr(template, "channel_name_format"):
                # EventTemplateConfig dataclass
                name_format = template.channel_name_format
            elif hasattr(template, "get"):
                # Dict with event_channel_name
                name_format = template.get("event_channel_name")

        if name_format:
            # Resolve using full template engine
            base_name = self._resolve_template(name_format, event)
        else:
            # Default format: "Away @ Home"
            home_name = event.home_team.short_name if event.home_team else "Home"
            away_name = event.away_team.short_name if event.away_team else "Away"
            base_name = f"{away_name} @ {home_name}"

        # Append keyword if present
        if exception_keyword:
            return f"{base_name} ({exception_keyword.title()})"

        return base_name

    def _resolve_logo_url(
        self,
        event: Event,
        template,
    ) -> str | None:
        """Resolve logo URL from template.

        Uses full template engine for variable resolution.
        Falls back to home team logo if no template.

        Args:
            event: Event data
            template: Can be dict, EventTemplateConfig dataclass, or None
        """
        logo_url = None
        if template:
            # Handle both dict and dataclass template types
            if hasattr(template, "event_channel_logo_url"):
                # EventTemplateConfig dataclass
                logo_url = template.event_channel_logo_url
            elif hasattr(template, "get"):
                # Dict with event_channel_logo_url
                logo_url = template.get("event_channel_logo_url")

        if logo_url and "{" in logo_url:
            # Has template variables - resolve them
            resolved = self._resolve_template(logo_url, event)

            # Check if resolution succeeded (no unresolved placeholders)
            if "{" not in resolved:
                return resolved

        if logo_url:
            # Static URL - use as-is
            return logo_url

        # Fallback to home team logo
        if event.home_team and event.home_team.logo_url:
            return event.home_team.logo_url

        return None

    def _resolve_template(self, template_str: str, event: Event) -> str:
        """Resolve template string using full template engine.

        Supports all 141 template variables.

        Args:
            template_str: Template string with {variable} placeholders
            event: Event to extract context from

        Returns:
            Resolved string with variables replaced
        """
        context = self._context_builder.build_for_event(
            event=event,
            team_id=event.home_team.id if event.home_team else "",
            league=event.league,
        )
        return self._resolver.resolve(template_str, context)

    def _get_next_channel_number(
        self,
        conn: Connection,
        group_id: int,
        group_start_number: int | None = None,
    ) -> int | None:
        """Get next available channel number for a group.

        Uses the channel_numbers module for AUTO/MANUAL mode support
        with range validation and 10-block intervals.

        Args:
            conn: Database connection
            group_id: Event EPG group ID
            group_start_number: Starting channel number from group config (unused, read from DB)

        Returns:
            Next available channel number as int, or None if range exhausted
        """
        from teamarr.database.channel_numbers import get_next_channel_number

        next_num = get_next_channel_number(conn, group_id, auto_assign=True)
        if next_num is None:
            logger.warning(f"Could not allocate channel number for group {group_id}")
            return None
        return next_num

    def _sync_channel_settings(
        self,
        conn: Connection,
        existing: Any,
        stream: dict,
        event: Event,
        group_config: dict,
        template: dict | None,
    ) -> StreamProcessResult:
        """Sync channel settings from group/template to Dispatcharr.

        V1 Parity: Syncs all 8 channel properties:
        | Source              | Dispatcharr Field    | Handling                    |
        |---------------------|---------------------|-----------------------------|
        | template            | name                | Template variable resolution|
        | group.channel_start | channel_number      | Range validation/reassign   |
        | group               | channel_group_id    | Simple compare              |
        | group               | stream_profile_id   | Simple compare              |
        | current_stream      | streams             | M3U ID lookup               |
        | group               | channel_profile_ids | Add/remove via profile API  |
        | template            | logo_id             | Upload/update if different  |
        | event_id            | tvg_id              | Ensures EPG matching        |
        """
        from teamarr.database.channel_numbers import (
            get_group_channel_range,
            get_next_channel_number,
            validate_channel_in_range,
        )
        from teamarr.database.channels import (
            log_channel_history,
            update_managed_channel,
        )

        result = StreamProcessResult()

        if not self._channel_manager:
            return result

        try:
            with self._dispatcharr_lock:
                current_channel = self._channel_manager.get_channel(existing.dispatcharr_channel_id)
                if not current_channel:
                    return result

            update_data = {}
            db_updates = {}
            changes_made = []
            group_id = group_config.get("id")

            # 1. Check channel name (template resolution) - V1 parity
            matched_keyword = getattr(existing, "exception_keyword", None)
            expected_name = self._generate_channel_name(event, template, matched_keyword)
            if expected_name != current_channel.name:
                update_data["name"] = expected_name
                db_updates["channel_name"] = expected_name
                changes_made.append(f"name: {current_channel.name} → {expected_name}")

            # 2. Check channel number (range validation/reassign) - V1 parity
            current_number = (
                int(current_channel.channel_number) if current_channel.channel_number else None
            )
            if current_number and group_id:
                if not validate_channel_in_range(conn, group_id, current_number):
                    # Channel is out of range - reassign
                    new_number = get_next_channel_number(conn, group_id, auto_assign=False)
                    if new_number:
                        update_data["channel_number"] = new_number
                        db_updates["channel_number"] = new_number
                        changes_made.append(
                            f"number: {current_number} → {new_number} (range reassign)"
                        )

                        # Log range reassignment
                        range_start, range_end = get_group_channel_range(conn, group_id)
                        logger.info(
                            f"Channel '{existing.channel_name}' reassigned: "
                            f"{current_number} → {new_number} (range {range_start}-{range_end})"
                        )

            # 3. Check channel_group_id
            new_group_id = group_config.get("channel_group_id")
            old_group_id = current_channel.channel_group_id
            if new_group_id != old_group_id:
                update_data["channel_group_id"] = new_group_id
                changes_made.append(f"channel_group_id: {old_group_id} → {new_group_id}")

            # 4. Check stream_profile_id
            new_profile_id = group_config.get("stream_profile_id")
            old_profile_id = current_channel.stream_profile_id
            if new_profile_id != old_profile_id:
                update_data["stream_profile_id"] = new_profile_id
                changes_made.append(f"stream_profile_id: {old_profile_id} → {new_profile_id}")

            # 5. Check streams (M3U ID sync) - V1 parity
            stream_id = stream.get("id") if stream else None
            if stream_id:
                # streams is already tuple[int, ...] of stream IDs
                ch_streams = current_channel.streams
                current_stream_ids = list(ch_streams) if ch_streams else []
                if stream_id not in current_stream_ids:
                    # Stream changed - update to use current stream
                    # Note: For consolidate mode, this adds streams; for separate, this replaces
                    new_streams = current_stream_ids + [stream_id]
                    update_data["streams"] = new_streams
                    db_updates["dispatcharr_stream_id"] = stream_id
                    changes_made.append(f"streams: added {stream_id}")

            # 6. Check tvg_id
            expected_tvg_id = existing.tvg_id
            if expected_tvg_id != current_channel.tvg_id:
                update_data["tvg_id"] = expected_tvg_id
                changes_made.append(f"tvg_id: {current_channel.tvg_id} → {expected_tvg_id}")

            # Apply Dispatcharr updates
            if update_data:
                with self._dispatcharr_lock:
                    self._channel_manager.update_channel(
                        existing.dispatcharr_channel_id,
                        update_data,
                    )

            # Apply DB updates
            if db_updates:
                update_managed_channel(conn, existing.id, db_updates)

            # 7. Sync channel_profile_ids - V1 parity
            group_profile_ids = self._parse_profile_ids(group_config.get("channel_profile_ids"))
            stored_profile_ids = self._parse_profile_ids(
                getattr(existing, "channel_profile_ids", None)
            )

            profiles_to_add = set(group_profile_ids) - set(stored_profile_ids)
            profiles_to_remove = set(stored_profile_ids) - set(group_profile_ids)

            if profiles_to_add or profiles_to_remove:
                with self._dispatcharr_lock:
                    for profile_id in profiles_to_remove:
                        try:
                            self._channel_manager.remove_from_profile(
                                profile_id, existing.dispatcharr_channel_id
                            )
                            changes_made.append(f"removed from profile {profile_id}")
                        except Exception as e:
                            logger.debug(f"Failed to remove channel from profile {profile_id}: {e}")

                    for profile_id in profiles_to_add:
                        try:
                            self._channel_manager.add_to_profile(
                                profile_id, existing.dispatcharr_channel_id
                            )
                            changes_made.append(f"added to profile {profile_id}")
                        except Exception as e:
                            logger.debug(f"Failed to add channel to profile {profile_id}: {e}")

                # Update stored profile IDs in DB
                if group_profile_ids != stored_profile_ids:
                    update_managed_channel(
                        conn, existing.id, {"channel_profile_ids": json.dumps(group_profile_ids)}
                    )

            # 8. Sync logo - V1 parity
            logo_url = self._resolve_logo_url(event, template)
            if logo_url and self._logo_manager:
                current_logo_id = getattr(existing, "dispatcharr_logo_id", None)
                # Check if logo needs update (URL changed or no logo set)
                stored_logo_url = getattr(existing, "logo_url", None)
                if logo_url != stored_logo_url:
                    with self._dispatcharr_lock:
                        # Upload new logo
                        logo_result = self._logo_manager.upload(
                            name=f"{existing.channel_name} Logo",
                            url=logo_url,
                        )
                        if logo_result.success and logo_result.logo:
                            new_logo_id = logo_result.logo.get("id")
                            # Update channel with new logo
                            self._channel_manager.update_channel(
                                existing.dispatcharr_channel_id,
                                {"logo_id": new_logo_id},
                            )
                            # Update DB
                            update_managed_channel(
                                conn,
                                existing.id,
                                {
                                    "logo_url": logo_url,
                                    "dispatcharr_logo_id": new_logo_id,
                                },
                            )
                            changes_made.append("logo updated")

                            # Delete old logo if it existed
                            if current_logo_id:
                                try:
                                    self._logo_manager.delete(current_logo_id)
                                except Exception:
                                    pass  # Ignore logo deletion failures

            # Log changes if any
            if changes_made:
                result.settings_updated.append(
                    {
                        "channel_id": existing.dispatcharr_channel_id,
                        "channel_name": existing.channel_name,
                        "changes": changes_made,
                    }
                )

                # Log to history
                log_channel_history(
                    conn=conn,
                    managed_channel_id=existing.id,
                    change_type="synced",
                    change_source="epg_generation",
                    notes=f"Settings synced: {', '.join(changes_made)}",
                )

        except Exception as e:
            logger.debug(f"Error syncing settings for channel {existing.channel_name}: {e}")

        return result

    def delete_managed_channel(
        self,
        conn: Connection,
        managed_channel_id: int,
        reason: str = "scheduled",
    ) -> bool:
        """Delete a managed channel from Dispatcharr and mark as deleted in DB.

        V1 Parity: Also deletes the channel's logo from Dispatcharr.

        Args:
            conn: Database connection
            managed_channel_id: Managed channel ID
            reason: Deletion reason

        Returns:
            True if deleted successfully
        """
        from teamarr.database.channels import (
            get_managed_channel,
            log_channel_history,
            mark_channel_deleted,
        )

        channel = get_managed_channel(conn, managed_channel_id)
        if not channel:
            return False

        # Delete logo from Dispatcharr (V1 parity)
        logo_id = getattr(channel, "dispatcharr_logo_id", None)
        if self._logo_manager and logo_id:
            try:
                with self._dispatcharr_lock:
                    self._logo_manager.delete(logo_id)
            except Exception as e:
                logger.debug(f"Failed to delete logo {logo_id}: {e}")

        # Delete channel from Dispatcharr
        if self._channel_manager and channel.dispatcharr_channel_id:
            with self._dispatcharr_lock:
                result = self._channel_manager.delete_channel(channel.dispatcharr_channel_id)
                if not result.success:
                    logger.warning(
                        f"Failed to delete channel {channel.dispatcharr_channel_id} "
                        f"from Dispatcharr: {result.error}"
                    )

        # Mark as deleted in DB
        mark_channel_deleted(conn, managed_channel_id, reason)

        # Log history
        log_channel_history(
            conn=conn,
            managed_channel_id=managed_channel_id,
            change_type="deleted",
            change_source="lifecycle",
            notes=f"Deleted: {reason}",
        )

        logger.info(f"Deleted channel '{channel.channel_name}' ({reason})")
        return True

    def process_scheduled_deletions(self) -> StreamProcessResult:
        """Process all channels past their scheduled delete time.

        Returns:
            StreamProcessResult with deleted channels
        """
        from teamarr.database.channels import get_channels_pending_deletion

        result = StreamProcessResult()

        try:
            with self._db_factory() as conn:
                channels = get_channels_pending_deletion(conn)

                for channel in channels:
                    success = self.delete_managed_channel(
                        conn,
                        channel.id,
                        reason="scheduled_delete",
                    )

                    if success:
                        result.deleted.append(
                            {
                                "channel_id": channel.id,
                                "channel_name": channel.channel_name,
                                "tvg_id": channel.tvg_id,
                            }
                        )
                    else:
                        result.errors.append(
                            {
                                "channel_id": channel.id,
                                "channel_name": channel.channel_name,
                                "error": "Failed to delete",
                            }
                        )

        except Exception as e:
            logger.exception("Error processing scheduled deletions")
            result.errors.append({"error": str(e)})

        if result.deleted:
            logger.info(f"Deleted {len(result.deleted)} expired channels")

        return result

    def associate_epg_with_channels(self, epg_source_id: int | None = None) -> dict:
        """Associate EPG data with managed channels after EPG refresh.

        Looks up EPGData by tvg_id and calls set_channel_epg to link them.

        Args:
            epg_source_id: Optional EPG source ID (uses default from settings if not provided)

        Returns:
            Dict with success/error counts
        """
        from teamarr.database.channels import get_all_managed_channels

        if not self._channel_manager or not self._epg_manager:
            return {"error": "Dispatcharr not configured"}

        result = {"associated": 0, "not_found": 0, "errors": 0}

        with self._db_factory() as conn:
            # Get all active managed channels
            channels = get_all_managed_channels(conn, include_deleted=False)

            if not channels:
                return result

            # Build EPG data lookup from Dispatcharr (via ChannelManager)
            epg_lookup = self._channel_manager.build_epg_lookup(epg_source_id)

            for channel in channels:
                if not channel.dispatcharr_channel_id or not channel.tvg_id:
                    continue

                # Look up EPG data by tvg_id
                epg_data = epg_lookup.get(channel.tvg_id)

                if not epg_data:
                    result["not_found"] += 1
                    continue

                # Associate EPG with channel
                epg_data_id = epg_data.get("id")
                if not epg_data_id:
                    result["not_found"] += 1
                    continue

                try:
                    with self._dispatcharr_lock:
                        self._channel_manager.set_channel_epg(
                            channel.dispatcharr_channel_id,
                            epg_data_id,
                        )
                    result["associated"] += 1
                except Exception as e:
                    logger.debug(f"Failed to associate EPG for channel {channel.channel_name}: {e}")
                    result["errors"] += 1

        if result["associated"]:
            logger.info(f"Associated EPG data with {result['associated']} channels")

        return result

    def cleanup_deleted_streams(
        self,
        group_id: int,
        current_stream_ids: list[int],
    ) -> StreamProcessResult:
        """Clean up channels for streams that no longer exist in Dispatcharr.

        V1 Parity: Runs regardless of delete_timing because missing streams
        should trigger immediate deletion.

        Args:
            group_id: Event EPG group ID
            current_stream_ids: List of current stream IDs from Dispatcharr M3U

        Returns:
            StreamProcessResult with deleted channels and errors
        """
        from teamarr.database.channels import (
            get_channel_streams,
            get_managed_channels_for_group,
            log_channel_history,
            remove_stream_from_channel,
        )

        result = StreamProcessResult()
        current_ids_set = set(current_stream_ids)

        try:
            with self._db_factory() as conn:
                # Get all active channels for the group
                channels = get_managed_channels_for_group(conn, group_id)

                for channel in channels:
                    # Get streams associated with this channel
                    streams = get_channel_streams(conn, channel.id)

                    if not streams:
                        # Legacy fallback: check primary_stream_id
                        primary_id = getattr(channel, "primary_stream_id", None)
                        if primary_id and primary_id not in current_ids_set:
                            success = self.delete_managed_channel(
                                conn,
                                channel.id,
                                reason="primary stream removed",
                            )
                            if success:
                                result.deleted.append(
                                    {
                                        "channel_id": channel.dispatcharr_channel_id,
                                        "channel_number": channel.channel_number,
                                        "channel_name": channel.channel_name,
                                        "reason": "primary stream no longer exists",
                                    }
                                )
                        continue

                    # Separate into valid and missing streams
                    valid_streams = []
                    missing_streams = []
                    for s in streams:
                        stream_id = getattr(s, "dispatcharr_stream_id", None)
                        if stream_id and stream_id in current_ids_set:
                            valid_streams.append(s)
                        else:
                            missing_streams.append(s)

                    if not valid_streams:
                        # All streams gone - delete channel
                        success = self.delete_managed_channel(
                            conn,
                            channel.id,
                            reason="all streams removed",
                        )
                        if success:
                            result.deleted.append(
                                {
                                    "channel_id": channel.dispatcharr_channel_id,
                                    "channel_number": channel.channel_number,
                                    "channel_name": channel.channel_name,
                                    "reason": "all streams no longer exist",
                                }
                            )
                        else:
                            result.errors.append(
                                {
                                    "channel_id": channel.dispatcharr_channel_id,
                                    "error": "Failed to delete channel",
                                }
                            )

                    elif missing_streams:
                        # Some streams gone - remove them from channel
                        for missing in missing_streams:
                            stream_id = getattr(missing, "dispatcharr_stream_id", None)
                            if stream_id:
                                # Remove from DB
                                remove_stream_from_channel(conn, channel.id, stream_id)

                                # Remove from Dispatcharr
                                if self._channel_manager:
                                    with self._dispatcharr_lock:
                                        current = self._channel_manager.get_channel(
                                            channel.dispatcharr_channel_id
                                        )
                                        if current:
                                            # streams is tuple[int, ...] of IDs
                                            s = current.streams
                                            current_ids = list(s) if s else []
                                            if stream_id in current_ids:
                                                current_ids.remove(stream_id)
                                                self._channel_manager.update_channel(
                                                    channel.dispatcharr_channel_id,
                                                    {"streams": current_ids},
                                                )

                                # Log history
                                log_channel_history(
                                    conn=conn,
                                    managed_channel_id=channel.id,
                                    change_type="stream_removed",
                                    change_source="lifecycle",
                                    notes=f"Stream {stream_id} no longer exists",
                                )

                        result.streams_removed.append(
                            {
                                "channel_id": channel.dispatcharr_channel_id,
                                "channel_name": channel.channel_name,
                                "streams_removed": len(missing_streams),
                            }
                        )

        except Exception as e:
            logger.exception(f"Error cleaning up deleted streams for group {group_id}")
            result.errors.append({"error": str(e)})

        if result.deleted:
            logger.info(f"Deleted {len(result.deleted)} channels with missing streams")

        return result

    def reassign_group_channels(self, group_id: int) -> dict:
        """Reassign ALL channels in a group to their correct range.

        V1 Parity: Called during EPG generation when AUTO sort order changes
        or MANUAL start changes. Compacts channels to fill gaps.

        Args:
            group_id: Event EPG group ID

        Returns:
            Dict with reassigned, already_correct, and errors
        """
        from teamarr.database.channel_numbers import get_group_channel_range
        from teamarr.database.channels import (
            get_managed_channels_for_group,
            log_channel_history,
            update_managed_channel,
        )
        from teamarr.database.groups import get_group

        result = {
            "reassigned": [],
            "already_correct": [],
            "errors": [],
        }

        try:
            with self._db_factory() as conn:
                group = get_group(conn, group_id)
                if not group:
                    result["errors"].append({"error": f"Group {group_id} not found"})
                    return result

                # Get expected range for this group
                range_start, range_end = get_group_channel_range(conn, group_id)
                if range_start is None:
                    # No range configured - skip
                    return result

                # Get and sort active channels by current number
                channels = get_managed_channels_for_group(conn, group_id)
                if not channels:
                    return result

                # Sort by current channel number to maintain relative order
                sorted_channels = sorted(
                    channels, key=lambda c: int(c.channel_number) if c.channel_number else 9999
                )

                # Reassign to compact range
                next_number = range_start
                for channel in sorted_channels:
                    current_number = int(channel.channel_number) if channel.channel_number else None

                    if current_number == next_number:
                        # Already at correct position
                        result["already_correct"].append(
                            {
                                "channel_id": channel.dispatcharr_channel_id,
                                "channel_number": current_number,
                            }
                        )
                        next_number += 1
                        continue

                    # Check for overflow
                    if range_end and next_number > range_end:
                        result["errors"].append(
                            {
                                "channel_id": channel.dispatcharr_channel_id,
                                "channel_name": channel.channel_name,
                                "error": f"Range exhausted (max {range_end})",
                            }
                        )
                        continue

                    # Check Dispatcharr max
                    if next_number > 9999:
                        result["errors"].append(
                            {
                                "channel_id": channel.dispatcharr_channel_id,
                                "channel_name": channel.channel_name,
                                "error": "Exceeds Dispatcharr max (9999)",
                            }
                        )
                        continue

                    # Update Dispatcharr
                    if self._channel_manager:
                        with self._dispatcharr_lock:
                            self._channel_manager.update_channel(
                                channel.dispatcharr_channel_id,
                                {"channel_number": next_number},
                            )

                    # Update DB
                    update_managed_channel(conn, channel.id, {"channel_number": next_number})

                    # Log history
                    log_channel_history(
                        conn=conn,
                        managed_channel_id=channel.id,
                        change_type="modified",
                        change_source="lifecycle",
                        notes=f"Channel number: {current_number} → {next_number}",
                    )

                    result["reassigned"].append(
                        {
                            "channel_id": channel.dispatcharr_channel_id,
                            "channel_name": channel.channel_name,
                            "old_number": current_number,
                            "new_number": next_number,
                        }
                    )

                    next_number += 1

        except Exception as e:
            logger.exception(f"Error reassigning channels for group {group_id}")
            result["errors"].append({"error": str(e)})

        if result["reassigned"]:
            logger.info(f"Reassigned {len(result['reassigned'])} channels in group {group_id}")

        return result

    def reassign_all_auto_groups(self) -> dict:
        """Reassign ALL AUTO groups to their correct ranges.

        V1 Parity: Called at the start of EPG generation to ensure
        all AUTO groups have correct non-overlapping ranges based on
        current channel counts and sort order.

        This handles the case where:
        - Group A (sort=1) expands and needs more channels
        - Group B (sort=2) has channels in Group A's expanded range
        - Group B's channels must move to make room

        Returns:
            Dict with total stats across all groups
        """
        from teamarr.database.channel_numbers import (
            _calculate_blocks_needed,
            _get_total_stream_count,
            get_global_channel_range,
        )
        from teamarr.database.channels import (
            get_managed_channels_for_group,
            log_channel_history,
            update_managed_channel,
        )

        result = {
            "groups_processed": 0,
            "channels_reassigned": 0,
            "errors": [],
        }

        try:
            with self._db_factory() as conn:
                # Get global channel range
                range_start, range_end = get_global_channel_range(conn)

                # Get all AUTO groups sorted by sort_order
                auto_groups = conn.execute(
                    """SELECT id, name, sort_order
                       FROM event_epg_groups
                       WHERE channel_assignment_mode = 'auto'
                         AND parent_group_id IS NULL
                         AND enabled = 1
                       ORDER BY sort_order ASC"""
                ).fetchall()

                if not auto_groups:
                    return result

                # Calculate ideal ranges for each group based on raw stream count
                group_ranges = []
                current_start = range_start
                for grp in auto_groups:
                    group_id = grp["id"]
                    # Use total_stream_count (raw M3U) for range reservation
                    total_streams = _get_total_stream_count(conn, group_id)
                    blocks_needed = _calculate_blocks_needed(total_streams)
                    group_end = current_start + (blocks_needed * 10) - 1

                    group_ranges.append(
                        {
                            "id": group_id,
                            "name": grp["name"],
                            "ideal_start": current_start,
                            "ideal_end": group_end,
                            "stream_count": total_streams,
                        }
                    )

                    current_start = group_end + 1

                # Process each group and reassign channels if needed
                for grp_range in group_ranges:
                    group_id = grp_range["id"]
                    ideal_start = grp_range["ideal_start"]

                    # Get channels for this group sorted by current number
                    channels = get_managed_channels_for_group(conn, group_id)
                    if not channels:
                        continue

                    sorted_channels = sorted(
                        channels, key=lambda c: int(c.channel_number) if c.channel_number else 9999
                    )

                    # Reassign to ideal range
                    next_number = ideal_start
                    for channel in sorted_channels:
                        current_num = (
                            int(channel.channel_number) if channel.channel_number else None
                        )

                        if current_num == next_number:
                            next_number += 1
                            continue

                        # Need to reassign
                        if self._channel_manager:
                            with self._dispatcharr_lock:
                                self._channel_manager.update_channel(
                                    channel.dispatcharr_channel_id,
                                    {"channel_number": next_number},
                                )

                        update_managed_channel(conn, channel.id, {"channel_number": next_number})

                        log_channel_history(
                            conn=conn,
                            managed_channel_id=channel.id,
                            change_type="modified",
                            change_source="lifecycle",
                            notes=f"Channel number: {current_num} → {next_number}",
                        )

                        result["channels_reassigned"] += 1
                        next_number += 1

                    result["groups_processed"] += 1

        except Exception as e:
            logger.exception("Error in global AUTO group reassignment")
            result["errors"].append({"error": str(e)})

        if result["channels_reassigned"]:
            logger.info(
                f"Global reassignment: {result['channels_reassigned']} channels "
                f"across {result['groups_processed']} groups"
            )

        return result

    def cleanup_orphan_dispatcharr_channels(self) -> dict:
        """Clean up orphan channels in Dispatcharr.

        V1 Parity: Runs every EPG generation to find and delete orphan channels.

        Orphan channels are Dispatcharr channels with teamarr-event-* tvg_id
        that aren't tracked (or are tracked as deleted) in our DB.

        These can occur when:
        - Dispatcharr delete API call failed but DB was marked deleted
        - Same event got a new channel, old one wasn't cleaned up
        - Manual intervention or bugs

        Returns:
            Dict with 'deleted' count and 'errors' list
        """
        from teamarr.database.channels import get_all_managed_channels

        result = {"deleted": 0, "errors": []}

        if not self._channel_manager:
            return result

        try:
            with self._db_factory() as conn:
                # Get all teamarr channels from Dispatcharr
                with self._dispatcharr_lock:
                    all_dispatcharr = self._channel_manager.get_channels()

                teamarr_channels = [
                    c for c in all_dispatcharr if (c.tvg_id or "").startswith("teamarr-event-")
                ]

                if not teamarr_channels:
                    return result

                # Get active DB channels (by dispatcharr_channel_id and UUID)
                db_channels = get_all_managed_channels(conn, include_deleted=False)
                active_ids = {
                    c.dispatcharr_channel_id for c in db_channels if c.dispatcharr_channel_id
                }
                active_uuids = {c.dispatcharr_uuid for c in db_channels if c.dispatcharr_uuid}

                # Find orphans
                orphans = [
                    c
                    for c in teamarr_channels
                    if c.id not in active_ids and (not c.uuid or c.uuid not in active_uuids)
                ]

                if not orphans:
                    return result

                logger.info(f"Found {len(orphans)} orphan Dispatcharr channel(s) to clean up")

                for orphan in orphans:
                    try:
                        with self._dispatcharr_lock:
                            delete_result = self._channel_manager.delete_channel(orphan.id)

                        is_success = delete_result.success
                        is_not_found = "not found" in str(delete_result.error or "").lower()
                        if is_success or is_not_found:
                            result["deleted"] += 1
                            logger.debug(
                                f"Deleted orphan channel #{orphan.channel_number} - {orphan.name}"
                            )
                        else:
                            result["errors"].append(
                                {
                                    "channel_id": orphan.id,
                                    "channel_name": orphan.name,
                                    "error": delete_result.error,
                                }
                            )
                    except Exception as e:
                        result["errors"].append(
                            {
                                "channel_id": orphan.id,
                                "channel_name": orphan.name,
                                "error": str(e),
                            }
                        )

        except Exception as e:
            logger.exception("Error cleaning up orphan Dispatcharr channels")
            result["errors"].append({"error": str(e)})

        if result["deleted"] > 0:
            logger.info(f"Cleaned up {result['deleted']} orphan Dispatcharr channels")

        return result

    def cleanup_disabled_groups(self) -> dict:
        """Clean up channels from disabled event groups.

        When a group is DISABLED, channels are cleaned up at the next EPG
        generation rather than immediately. This allows users to re-enable
        the group without losing channels.

        V1 Parity: Matches cleanup_disabled_groups() from channel_lifecycle.py

        Returns:
            Dict with 'deleted' and 'errors' lists
        """
        from teamarr.database.channels import (
            get_managed_channels_for_group,
            mark_channel_deleted,
        )
        from teamarr.database.groups import get_all_groups

        result: dict = {"deleted": [], "errors": []}

        try:
            with self._db_factory() as conn:
                # Get ALL groups including disabled
                all_groups = get_all_groups(conn, include_disabled=True)

                # Filter to disabled groups only
                disabled_groups = [g for g in all_groups if not g.enabled]

                if not disabled_groups:
                    return result

                logger.info(
                    f"Checking {len(disabled_groups)} disabled group(s) for channel cleanup..."
                )

                for group in disabled_groups:
                    group_id = group.id
                    group_name = group.name

                    # Get channels for this disabled group
                    channels = get_managed_channels_for_group(
                        conn, group_id, include_deleted=False
                    )

                    for channel in channels:
                        try:
                            # Delete from Dispatcharr
                            if self._channel_manager and channel.dispatcharr_channel_id:
                                with self._dispatcharr_lock:
                                    self._channel_manager.delete_channel(
                                        channel.dispatcharr_channel_id
                                    )

                            # Mark as deleted in DB
                            mark_channel_deleted(
                                conn, channel.id, reason=f"Group '{group_name}' disabled"
                            )

                            result["deleted"].append(
                                {
                                    "group": group_name,
                                    "channel_number": channel.channel_number,
                                    "channel_name": channel.channel_name,
                                }
                            )
                        except Exception as e:
                            result["errors"].append(
                                {
                                    "group": group_name,
                                    "channel_id": channel.dispatcharr_channel_id,
                                    "error": str(e),
                                }
                            )

                conn.commit()

        except Exception as e:
            logger.exception("Error cleaning up disabled groups")
            result["errors"].append({"error": str(e)})

        if result["deleted"]:
            logger.info(
                f"Cleaned up {len(result['deleted'])} channel(s) from disabled groups"
            )

        return result

    def _parse_profile_ids(self, raw: Any) -> list[int]:
        """Parse channel profile IDs from various formats."""
        if not raw:
            return []
        if isinstance(raw, str):
            try:
                raw = json.loads(raw)
            except json.JSONDecodeError:
                return []
        if isinstance(raw, list):
            return [int(x) for x in raw if x]
        return []
